# flash attention re-implementation

This is a re-implementation of Flash Attention #1 with CUDA and PyTorch. The kernel is ran on NVIDIA RTX 4060. 



